## 实现总结

### 1. Provider 层流式支持 (`providers/openai_compatible.py`)

-   在 `call()` 方法中添加 `stream` 参数
-   添加 `_stream_response()` 方法处理流式响应
-   支持流式和非流式两种模式

### 2. 主程序流式输出 (`ask_llm.py`)

-   添加 `stream_response()` 函数：处理流式响应，实时打印并收集完整内容
-   添加 `clear_streamed_output()` 函数：使用 ANSI 转义码清空流式输出（支持多行）
-   修改 `main()` 函数：
    -   使用 `stream=True` 调用 API
    -   实时显示流式输出
    -   输出到文件时，在文件写入后清空终端中的流式输出

### 3. Chat 模式流式输出 (`chat_mode.py`)

-   修改 API 调用部分，使用流式模式
-   实时显示流式响应
-   收集完整响应用于添加到消息历史
-   不清空流式输出（保持对话连续性）

## 主要特性

1. 流式输出：API 响应实时显示在终端
2. 智能清空：输出到文件时，文件写入后自动清空终端中的流式输出
3. 多行支持：清空函数可处理多行响应
4. 终端检测：仅在 TTY 终端执行清空操作
5. Chat 模式：保持流式输出可见，不清空

代码已通过 lint 检查，无错误。可以开始测试流式输出功能。
